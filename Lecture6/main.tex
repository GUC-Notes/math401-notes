%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Problem Set/Assignment Template to be used by the
%% Food and Resource Economics Department - IFAS
%% University of Florida's graduates.
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Version 1.0 - November 2019
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Ariel Soto-Caro
%%  - asotocaro@ufl.edu
%%  - arielsotocaro@gmail.com
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}
\usepackage{design_ASC}

\theoremstyle{definition}
\usepackage{longtable}
\newtheorem{exmp}{Example}[section]
\newtheorem{slo}{Definition}[section]
\newcommand*{\Perm}[2]{{}^{#1}\!P_{#2}}%
\newcommand*{\Comb}[2]{{}^{#1}C_{#2}}%
\setlength\parindent{0pt} %% Do not touch this
\usepackage{amsmath}% http://ctan.org/pkg/amsmath
%% -----------------------------
%% TITLE
%% -----------------------------
\title{\textbf{Discrete Random variable}} %% Assignment Title

\author{\textbf{Ibrahim Abou Elenein}}

\date{\today} %% Change "\today" by another date manually
%% -----------------------------
%% -----------------------------

%% %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\setlength{\droptitle}{-5em}    
%% %%%%%%%%%%%%%%%%%%%%%%%%%
\maketitle

% --------------------------
% Start here
% --------------------------

% %%%%%%%%%%%%%%%%%%%
\section{Random Variable}
 A random variable is a quantity “X ” resulting from an experiment, by chance,
 that can assume different values.\\

 A random variable is a variable “X” that
 has a single numerical value determined by chance, for each outcome of a
 procedure.\\

 If a sample space S is discrete, then every R.V.  defined on S is
 also discrete, i.e., its range is countable (think of random counts for
 examples).
\section{Discrete Random Variable}
 A Discrete Random Variable is a variable that can assume only certain clearly
 separated values. \\

 A Discrete Random Variable has either a finite or countable
 number of values, where “countable” refers to the fact that there might be
 infinitely many values, but they can be associated with a counting process.
 \subsection{Examples of Discrete Random Variables}
 \begin{itemize}
     \item The outcome of rolling a single die.
     \item The number of boys in a family with three children.
     \item The number of heads that appear when a coin is flipped nine times.
     \item The sum of the numbers on the dice, when k dice are rolled.
     \item The number of bits received in error when n bits are received.
     \item The number of bits received until the r-th error.
 \end{itemize}
 \section{Discrete Probability Distributions}
A discrete probability distribution is a listing of 
all possible values of a random variable along 
with their probabilities. \\
\begin{equation}
    \displaystyle \frac{X}{P(X)} \frac{|x_1|}{|p_1|} \frac{|x_2|}{|p_2|} \frac{|x_2|}{|p_2|} 
    \frac{|\dots|}{|\dots|} \frac{|x_k|}{|p_k|}; \  \ \  \sum _{k \geq 1} p_k = 1.
\end{equation}    
\begin{enumerate}
    \item The sum of all probabilities must be 1in any probability distribution
    \item All probability values must be in [0,1]
\end{enumerate}
\begin{exmp}
    x $\Rightarrow$ The number of heads appearing when a coin is flipped three times.

\end{exmp}
    
% Please add the following required packages to your document preamble:
% Note: It may be necessary to compile the document several times to get a multi-page table to line up properly
\begin{longtable}[c]{lllll}
X    & 0   & 1   & 2   & 3   \\
\endfirsthead
%
\endhead
%
P(X) & 1/8 & 3/8 & 3/8 & 1/8
\end{longtable}

\subsection{Bernoulli}
A Bernoulli trail is an experiment with only two outcomes Success and Failure 
\begin{enumerate}
    \item $P(S) = p = $ Probability of a success
    \item $P(F) = q = 1 - p = $ Probability of a failure
\end{enumerate}
If a Bernoulli random variable, X, denotes No. of successes, then
\begin{enumerate}
    \item $ X = 1$ if the outcome is success
    \item $ X = 0$ if the outcome is failure
\end{enumerate}
\begin{exmp}
A bit is transmitted, it is received in error with probability “0.1”.\\
Assume that 8 bits are transmitted independently.
\begin{enumerate}
    \item How many bits can be received in error?
        \begin{center}
            $\Perm{8}{2}$
        \end{center}   
    \item What is the probability that 2 bits are received in error
        \begin{center}
            $P(X=2) = \Perm{8}{2} \times (0.1)^2 (0.9)^6  $  
        \end{center}   
\end{enumerate}
\end{exmp}    
\subsection{Binomial Distribution}
In general, let X stand for the number of bits received in error, when $n$ bits are transmitted,
with the probability of a single bit in error being $p$
\begin{equation}
    P (X = k) = \Comb{n}{k} \times p^k \times (1-p)^{n - k} 
\end{equation}    

\begin{equation}
    \sum_{k = 0}^{n} p_k  = \Comb{n}{k} \times p^k \times (1-p)^{n - k} = [(p)+(1-p)]^n = 1 ^ n = 1
\end{equation}    
\begin{exmp}
A fair coin is tossed 10 times, what is the probability of getting:
\begin{enumerate}
    \item  Exactly 6 heads.
        \begin{center}
            $ n = 10; \ \ p = 0.5; q = 0.5 $ 
        \end{center}   
        \begin{center}
            $P(X = 6) = \Comb{10}{6} \times (0.5)^6 \times (0.5)^4   $ 
        \end{center}   
    \item  At least 6 heads.
        \begin{center}
            $P(X \geq 6) = P(X = 6) + P(X = 7) + P(X = 8) + P(X = 9) + P(X = 10)  $
        \end{center}   
\end{enumerate}
\end{exmp}    

\subsection{Geometric Distribution}

A bit is transmitted, it is received in error with probability “0.1”.

Assume that bits are transmitted independently, until the first bit is received
in error.
\begin{enumerate}

    \item How many bits can be received?
        \begin{center}
            Infinity many many
        \end{center}
    \item What is the probability that the 5-th bit is received in error?
        \begin{center}
            $  P(X = 5) = 0.1 \times 0.9^4 $
        \end{center}
    \item What is the probability that at least 5 (i.e. 5 or more) bits are received until the first error
        \begin{center}
            $  P(X \geq 5) = P(X = 5) + P(X = 6) + \dots $  =
        \end{center}
        \begin{center}
            $  \displaystyle \sum_{k = 5}^{\infty} P(X = K) = \sum_{k = 5}^{\infty}(0.1)(0.9)^{k-1} = 0.656$
        \end{center}

\end{enumerate}
So The General case is 
\begin{equation}
    P(X = k) = p \times (1 - p)^{k-1} ; \ \ \ k \geq 1
\end{equation}    

\begin{equation}
    \displaystyle \sum_{k = 1}^{\infty}   P(X = k) = \sum_{k = 1}^{\infty}p \times (1 - p)^{k-1}
    = p\sum_{k = 1}^{\infty}(1 - p)^{k-1} = p \times \frac{1}{p} = 1
\end{equation}    
\begin{exmp}
    Given that the first $k$ trials were Failures. Find the probability that $(k+1)$-th trial will be a Success. \\

    we need to find that $P(X = k + 1 | X > k)$
    \begin{center}
        $ \displaystyle  P(X = k + 1 | X > k) = \frac{P(X=k+1 \cap X>k)}{P(X>k)}
        = \frac{p \times (1-p)^k}{(1-p)^k} = p = p(X = 1)$  this called lack of memory where the probability
        of k + 1 is the same as the first
\end{center}
\end{exmp}    
\subsection{Negative Binomial}
When a bit is transmitted, it is received in error with probability “0.1”.
Assume that bits are transmitted independently, until FOUR bits are received in error.
\begin{enumerate}
    \item At least, how many bits can be received ?
        \begin{center}
            at least 4 bits.
        \end{center}   
    \item What is the probability that exactly 10 bits will be received
        \begin{center}
            $  P(X= 10) = (0.1)^9 \times \Comb{9}{3} \times (0.9)^6 \times (0.1)^3 $
        \end{center}   
        In General, $P(X = k) = \Comb{k-1}{3} \times (1-p)^{k-4} \times p^4$

\end{enumerate}   
\begin{slo}
 In general, let X stand for the number of bits
received until r bits are received in error, with
the probability of a single bit in error being p.
\end{slo}   
\begin{equation}
    P(X = k) =  \underbrace{p^r}_{\text{last trial}} 
    \ \ \underbrace{\Comb{k-1}{r-1} (1-p)^{k-r}}_{\text{(r - 1)success in(k - 1)trial}}; \ \ k \geq r. 
\end{equation}
\begin{equation}
    \displaystyle \sum_{k=r}^{\infty} \Comb{k-1}{r-1} p^r(1-p)^{k-r} =
    \sum_{k' = 0}^{\infty} \Comb{k' + r -1}{k'} \ p^r (1-p)^{k'}
\end{equation}
given that $ \displaystyle \Comb{n}{k} = \Comb{n}{n- k}$

\begin{equation}
    \displaystyle \sum_{k' = 0}^{\infty} \Comb{k' + r -1}{k'} \ p^r (1-p)^{k'} =
    p^r \sum_{k'= 0}^{\infty}  \Comb{k' + r-1}{r-1}(1-p)^{k'}
\end{equation}
given that $ \displaystyle \frac{1}{(1-x)^r} = \sum_{k=0}^{\infty} \Comb{k+r-1}{r-1}x^r $
\begin{equation}
    \displaystyle p^r \sum_{k'= 0}^{\infty}  \Comb{k' + r-1}{r-1}(1-p)^{k'} = p^r * \frac{1}{(1-(1-p))^r} = 1 
\end{equation}
\end{document}
